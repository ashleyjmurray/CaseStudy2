---
title: "Analysis"
author: "Steven Herrera Tenorio, Ashley Murray, Nathan O'Hara"
fontsize: 12pt
geometry: "left=1.5cm,right=1.5cm,top=1.5cm,bottom=1.5cm"
output: 
  pdf_document:
     latex_engine: xelatex
     number_sections: true
---

```{r package_test, include=FALSE}
# Validate that all necessary packaged have been downloaded, install otherwise or throw err package DNE
pkgTest <- function(x) {
  if (!require(x,character.only = TRUE))
    {
    install.packages(x,repos = "http://cran.r-project.org", dep=TRUE)
    if(!require(x,character.only = TRUE)) stop("Package not found")
    }
}
pkgTest("tidyverse")
pkgTest("cowplot")
pkgTest("reticulate")
pkgTest("ggfortify")
pkgTest("ggplot2")
pkgTest("dplyr")
pkgTest("tidyr")
pkgTest("broom")
pkgTest("car")
pkgTest("olsrr")
pkgTest("corrplot")
pkgTest("reshape2")
pkgTest("caret")
pkgTest("gridExtra")
pkgTest("gridGraphics")
pkgTest("grid")
pkgTest("kableExtra")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)
ggplot2::theme_set(new = theme_bw())
library(tidyverse)
library(cowplot)
library(reticulate)
library(ggfortify)
library(ggplot2)
library(dplyr)
library(tidyr)
library(broom)
library(car)
library(olsrr)
library(corrplot)
library(reshape2)
library(caret)
library(gridExtra)
library(gridGraphics)
library(grid)
library(kableExtra)
#py_install("pandas")
```

```{r load_data, include=FALSE}
#raw_stress_data <- read_csv("/Volumes/G-DRIVE mobile/CaseStudy2/amusement_and_stress.csv") %>% 
  #mutate(label = as.factor(label))
final <- read_csv("/Volumes/G-DRIVE mobile/CaseStudy2/final.csv") %>% 
  mutate(label = as.factor(label))
data_table <- read_csv("/Volumes/G-DRIVE mobile/CaseStudy2/data_table.csv", 
                       col_names = c("Sensor", "Features", "Count"))
```

# Introduction

Wearable technologies have become increasingly prevalent in recent years, with public interest taking note of the accessibility, health interests, and innovation [[1]][Bibliography], especially with products such as the Apple Watch. While these devices are commonly marketed as a valuable communication interface for their users, they also provide a wide array of health monitoring features, such as electrocardiography (ECG) [[2]][Bibliography], heart rate variability (HRV) [[3]][Bibliography], and accelerometry (ACC) [[4]][Bibliography]. Therefore, health-conscious consumers have increasingly adopted wearables [[1,5,6]][Bibliography]. For example, in a study exploring consumers' health beliefs and percieved usefulness of wearable healthcare technology, Cheung et al. (2019) found that consumers cite health information accuracy as a primary motivating factor for wearable use [[7]][Bibliography].

One line of scholarship is focused on the effectiveness of detecting stress through wearable technologies [[8]][Bibliography]. Stress, in our definition, is a critical mental and physical state of health, denoted from a historical understanding of a "general anxiety" [[9]][Bibliography]. It is well-established that stress leads to a number of long-term health conditions, ranging from headaches and sleep issues to an increased risk of cardiovascular disease [[2,5,8]][Bibliography]. For this reason, researchers have been interested in establishing and interpreting models to predict the affective state of stress using information from wearable devices [[8]][Bibliography].

A challenge in the detection of stress from wearable data is its physiological similarity to the state of amusement [[10]][Bibliography]. The two states share physiological responses to stimuli that trigger a mixture of hormones like cortisol and adrenaline, thus increasing heart rate and muscle tension [[3,8]][Bibliography], which may be difficult to discern in biological monitoring data [[11]][Bibliography]. For that reason, this paper will focus on building a model to discern between a state of stress and a state of amusement using the WESAD database [[8]][Bibliography], which used the **RespiBAN Professional** chest-device and **Empatica E4** wrist-device to collect sensor data. We expand upon previous work by performing more extensive feature engineering, addressing missing data considerations with a K-Nearest Neighbors upsampling strategy, and improving predictive accuracy using a stacking ensemble method. In addition to determining whether the engineered features in discriminating between stress and amusement were *useful*, we also want to answer *how* they were useful, which ones were *most* useful, if detecting between the states is effective using only the **Empatica E4** data, and a quantified analysis of the heterogeneity across individuals in the dataset.

# Data

## Description

Raw sensor data was recorded on seventeen subjects that participated in the study. However, data of two of the subjects had to be discarded due to sensor malfunction. The data was recorded for each of the subjects with two different devices: RespiBAN, a chest-worn device, and Empatica E4, a wrist-worn device. Within this data analysis, we focused on the synchronised raw sensor data labels, which was created by subjects performing a double tapping gesture with their non-dominant hand on their chest.

## Feature Extraction

Feature extraction 

was performed on the raw signal data in order to derive important aspects concerning the data that are often used by medical professionals to evaluate the health of their patients (cite this). Feature extraction was performed for some of the raw sensor data with the Python package neurokit2 (CITE the package), and by Python functions provided in the Appendix with (CITE THIS).

Rather than downsampling and lowering the sampling rate of the raw signals that were sampled at a higher frequency, we performed feature extraction using rolling subsetted windows.

The raw signal data was subsetted into 100-second rolling windows in Python, referenced in the Appendix (what figure). It was necessary to subset the data into the 100-second windows in order to calculate the features for each of the windows, which is a methodology practiced by (AUTHORS) in the (WESAD PAPER). Additionally, the method of subsetting signal data into windows is performed by Apple when the Apple Watch measures the mean ECG of its users. 100-second windows were chosen because of the necessity to extract features that made sense, as with not enough data, the features extracted would not make sense in the scope of the problem. (i.e. add more about how it wouldn’t make sense intuitively )

```{r}
data_table %>%
  kableExtra::kable(booktabs = T,
                    caption = "Feature Engineering with the WESAD Sensor Data",
                    col.names = c("Sensors", "Features", "# of features")) %>%
  kable_styling(latex_options = c("hold_position")) %>%
  kable_styling(font_size = 9) %>%
  pack_rows("RespiBAN Professional", 1, 4) %>%
  pack_rows("Empatica E4", 5, 8) %>%
  footnote(symbol = "HR/V = Heart rate/variability | SCL/R = Skin conductance level/response | I/EHD = Inhale/exhale duration") %>% 
  row_spec(0, bold = TRUE)
```




#### should we connect what was said about the window stuff (above) with this paragraph?

Feature Extraction was performed on the raw signal data, in order to derive important aspects concerning the data that are often used by medical professionals to evaluate the health of their patients (cite this). Feature extraction was performed for some of the raw sensor data with the Python package neurokit2 (CITE the package), and by Python functions provided in the Appendix with (CITE THIS). 

## Exploratory Data Analysis



















### Correlations

```{r correlations, warning=FALSE}
# remove columns w NAs, remove subject, remove identifier column X1
final_na <- final[, colSums(is.na(final)) != nrow(final)] %>% dplyr::select(-subject, -X1)

# remove label (the amusemet or stress identifier variable) to do correlation analysis
final_na$label <- NULL
# rename
d <- final_na
# apply correlations
zv <- apply(final_na, 2, function(x) length(unique(x)) == 1)
dfr <- final_na[, !zv]
n=length(colnames(dfr))
corr.d <- cor(dfr[,1:n],use="complete.obs")
# NAs on the diagonal
corr.d[ lower.tri( corr.d, diag = TRUE ) ] <- NA

# # sort pairs of correlated variables
# m <- melt(corr.d)
# m <- m[order(- abs(m$value)), ]
# # get rid of NAs
# m <- na.omit(m)
# # view the highest correlated: correlation vals > 0.75
# (check <- as.data.frame(m[ which( m$value > 0.80 ), ]))

# plot the correlations (it looks messy)
corrplot(corr.d, type = "upper", diag = FALSE , method = "color",
         tl.pos = "td", tl.cex = 0.25)
```

```{r}
# recall corr without the diagonal transformation
corr.d <- cor(dfr[,1:n],use="complete.obs")
# determine the variables most important with cutoff at 0.7
highlyCorrelated <- findCorrelation(corr.d, cutoff=(0.7),verbose = FALSE)
important_var <- colnames(corr.d[,-highlyCorrelated])
non_important_var <- colnames(corr.d[,highlyCorrelated])

# recreate the correlation plot
final_select <- final_na %>%
  select(c(important_var))

# apply correlations
zv1 <- apply(final_select, 2, function(x) length(unique(x)) == 1)
dfr1 <- final_select[, !zv1]
n=length(colnames(dfr1))
corr.d1 <- cor(dfr1[,1:n],use="complete.obs")
# NAs on the diagonal
corr.d1[ lower.tri( corr.d1, diag = TRUE ) ] <- NA

corrplot(corr.d1, type = "upper", diag = FALSE , method = "color",
         tl.pos = "td", tl.cex = 0.25)
```

```{r}
# recreate the correlation plot
final_select1 <- final_na %>%
  select(c(non_important_var))

# apply correlations
zv1 <- apply(final_select1, 2, function(x) length(unique(x)) == 1)
dfr1 <- final_select1[, !zv1]
n=length(colnames(dfr1))
corr.d12 <- cor(dfr1[,1:n],use="complete.obs")
# NAs on the diagonal
corr.d12[ lower.tri( corr.d12, diag = TRUE ) ] <- NA

corrplot(corr.d12, type = "upper", diag = FALSE , method = "color",
         tl.pos = "td", tl.cex = 0.25)
```





































# Methodology

# Results

# Cross-Validation // Sensitivity Analysis(?)

# Conclusion & Limitations

# Appendix


## Bibliography

1. Lee, Sang Yup, and Keeheon Lee. “Factors That Influence an Individual's Intention to Adopt a Wearable Healthcare Device: The Case of a Wearable Fitness Tracker.” Technological Forecasting &amp; Social Change, vol. 129, 2018, pp. 154–163., doi:10.1016/j.techfore.2018.01.002.

2. Murphy, Jane Louise, et al. “The Use of Wearable Technology to Measure Energy Expenditure, Physical Activity, and Sleep Patterns in Dementia.” Alzheimer's &amp; Dementia: The Journal of the Alzheimer's Association, vol. 11, no. 7, 2015, pp. P188–P188., doi:10.1016/j.jalz.2015.07.165.

3. Nixon, Jim, and Rebecca Charles. “Understanding the Human Performance Envelope Using Electrophysiological Measures from Wearable Technology.” Cognition, Technology &amp; Work, vol. 19, no. 4, 2017, pp. 655–666., doi:10.1007/s10111-017-0431-5.

4. Prieto, L. P., et al. “Multimodal Teaching Analytics: Automated Extraction of Orchestration Graphs from Wearable Sensor Data.” Journal of Computer Assisted Learning, vol. 34, no. 2, 2018, pp. 193–203., doi:10.1111/jcal.12232. Accessed 29 Sept. 2020. 

5. Jakicic, John M., et al. “Effect of Wearable Technology Combined With a Lifestyle Intervention on Long-Term Weight Loss: The IDEA Randomized Clinical Trial.” JAMA : the Journal of the American Medical Association, vol. 316, no. 11, 2016, pp. 1161–1171., doi:10.1001/jama.2016.12858.

6. Bai, Yang, et al. “Comparative Evaluation of Heart Rate-Based Monitors: Apple Watch vs Fitbit Charge HR.” Journal of Sports Sciences, vol. 36, no. 15, 2017, pp. 1734–1741., doi:10.1080/02640414.2017.1412235.

7. Cheung, Man Lai, et al. “Examining Consumers’ Adoption of Wearable Healthcare Technology: The Role of Health Attributes.” International Journal of Environmental Research and Public Health, vol. 16, no. 13, 2019, p. 2257., doi:10.3390/ijerph16132257.

8. Schmidt, Philip, et al. “Introducing WESAD, a Multimodal Dataset for Wearable Stress and Affect Detection.” Proceedings of the 2018 on International Conference on Multimodal Interaction - ICMI '18, 2018, doi:10.1145/3242969.3242985. 

9. Abbott, Andrew. “Positivism and Interpretation in Sociology: Lessons for Sociologists from the History of Stress Research.” Sociological Forum (Randolph, N.J.), vol. 5, no. 3, 1990, pp. 435–458., doi:10.1007/BF01115095.

10. Schmidt, Philip, et al. “Wearable-Based Affect Recognition—A Review.” Sensors, vol. 19, no. 19, 2019, p. 4079., doi:10.3390/s19194079. 

11. Schmidt, Philip, et al. “Labelling Affective States ‘in the Wild.’” Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers - UbiComp '18, 2018, doi:10.1145/3267305.3267551. 



