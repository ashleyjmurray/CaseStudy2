{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Modeling For Case Study 2\n",
    "Here is the order of things to do:\n",
    "\n",
    "## Main Model for Differentiating Stress / Amusement -- all vars\n",
    "- Import final.csv and process into X and Y matrices\n",
    "- GridSearchCV to find best LogisticRegression with L1 penalty\n",
    "- Make table of coefficients, p-values, 95% confidence intervals based on this regression\n",
    "- GridSearchCV to find best XGBoost model \n",
    "- Feature importance table from XGBoost\n",
    "- Try number of SVMs, GridSearchCV on polynomial order\n",
    "- Plot out CV predicted probas to see if it seems like an ensemble method would work\n",
    "- Fit PLS, fit classifiers on PLS inputs alone\n",
    "- Train StackingClassifier ensemble model\n",
    "\n",
    "- Figure out what tables we want, get the data formatted into CSVs and send them out.\n",
    "\n",
    "## Chest Only Model\n",
    "- Same approach as in the first part, only removing the features that aren't in the chest\n",
    "\n",
    "## Quantify Heterogeneity Across Individuals in Response to Stress vs. Amusement\n",
    "- Somehow make interaction terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(440)\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"final_updated_large.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0 0\n",
      "ECG_Rate_Mean 0\n",
      "HRV_RMSSD 0\n",
      "HRV_MeanNN 0\n",
      "HRV_SDNN 0\n",
      "HRV_SDSD 0\n",
      "HRV_CVNN 0\n",
      "HRV_CVSD 0\n",
      "HRV_MedianNN 0\n",
      "HRV_MadNN 0\n",
      "HRV_MCVNN 0\n",
      "HRV_IQRNN 0\n",
      "HRV_pNN50 0\n",
      "HRV_pNN20 0\n",
      "HRV_TINN 0\n",
      "HRV_HTI 0\n",
      "HRV_ULF 274\n",
      "HRV_VLF 274\n",
      "HRV_LF 274\n",
      "HRV_HF 3\n",
      "HRV_VHF 3\n",
      "HRV_LFHF 274\n",
      "HRV_LFn 274\n",
      "HRV_HFn 3\n",
      "HRV_LnHF 3\n",
      "HRV_SD1 0\n",
      "HRV_SD2 0\n",
      "HRV_SD1SD2 0\n",
      "HRV_S 0\n",
      "HRV_CSI 0\n",
      "HRV_CVI 0\n",
      "HRV_CSI_Modified 0\n",
      "HRV_PIP 0\n",
      "HRV_IALS 0\n",
      "HRV_PSS 0\n",
      "HRV_PAS 0\n",
      "HRV_GI 0\n",
      "HRV_SI 0\n",
      "HRV_AI 0\n",
      "HRV_PI 0\n",
      "HRV_C1d 0\n",
      "HRV_C1a 0\n",
      "HRV_SD1d 0\n",
      "HRV_SD1a 0\n",
      "HRV_C2d 0\n",
      "HRV_C2a 0\n",
      "HRV_SD2d 0\n",
      "HRV_SD2a 0\n",
      "HRV_Cd 0\n",
      "HRV_Ca 0\n",
      "HRV_SDNNd 0\n",
      "HRV_SDNNa 0\n",
      "HRV_ApEn 0\n",
      "HRV_SampEn 0\n",
      "eda_mean_chest 0\n",
      "eda_std_chest 0\n",
      "eda_min_chest 0\n",
      "eda_max_chest 0\n",
      "eda_slope_chest 0\n",
      "eda_range_chest 0\n",
      "eda_mean_scl_chest 0\n",
      "eda_std_scl_chest 0\n",
      "eda_std_scr_chest 0\n",
      "eda_scl_corr_chest 0\n",
      "eda_num_scr_seg_chest 0\n",
      "eda_sum_startle_mag_chest 0\n",
      "eda_sum_response_time_chest 0\n",
      "eda_sum_response_areas_chest 0\n",
      "eda_mean_wr 0\n",
      "eda_std_wr 0\n",
      "eda_min_wr 0\n",
      "eda_max_wr 0\n",
      "eda_slope_wr 0\n",
      "eda_range_wr 0\n",
      "eda_mean_scl_wr 0\n",
      "eda_std_scl_wr 0\n",
      "eda_std_scr_wr 0\n",
      "eda_scl_corr_wr 0\n",
      "eda_num_scr_seg_wr 0\n",
      "eda_sum_startle_mag_wr 0\n",
      "eda_sum_response_time_wr 0\n",
      "eda_sum_response_areas_wr 0\n",
      "resp_rate 3\n",
      "mean_inhale_duration 0\n",
      "std_inhale_duration 0\n",
      "mean_exhale_duration 0\n",
      "std_exhale_duration 0\n",
      "ie_ratio 3\n",
      "resp_stretch 0\n",
      "temp_wr_mean 0\n",
      "temp_wr_standard_deviation 0\n",
      "temp_wr_tenth_quantile 0\n",
      "temp_wr_nintieth_quantile 0\n",
      "temp_wr_range 0\n",
      "temp_chest_mean 0\n",
      "temp_chest_standard_deviation 0\n",
      "temp_chest_tenth_quantile 0\n",
      "temp_chest_nintieth_quantile 0\n",
      "temp_chest_range 0\n",
      "acc_x_mean 0\n",
      "acc_y_mean 0\n",
      "acc_z_mean 0\n",
      "acc_square_root 0\n",
      "subject 0\n",
      "label 0\n",
      "Dropped 6 columns\n"
     ]
    }
   ],
   "source": [
    "# Removing columns with NA values\n",
    "na_cols = []\n",
    "for col in final.columns:\n",
    "    numnas = sum(final[col].isna())\n",
    "    print(col, numnas)\n",
    "    if numnas > 5:\n",
    "        na_cols.append(col)\n",
    "na_cols.extend([\"Unnamed: 0\"])\n",
    "final = final.drop(columns = na_cols)\n",
    "print(\"Dropped\", len(na_cols), \"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummies for subject\n",
    "final[\"subject\"] = final[\"subject\"].astype(\"category\")\n",
    "final = pd.get_dummies(final, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    184\n",
       "0     90\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert label to 1 for stress, 0 for amusement\n",
    "final[\"label\"] = (final[\"label\"] == 2.0).astype(int)\n",
    "final[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_to_mean(X):\n",
    "    \"\"\"\n",
    "    Takes numpy array X and returns a version replacing inf and na values with their column means\n",
    "    \"\"\"\n",
    "    X = np.nan_to_num(X, nan = np.nan, posinf = np.nan)\n",
    "    col_mean = np.nanmean(X, axis = 0)\n",
    "    inds = np.where(np.isnan(X)) \n",
    "    X[inds] = np.take(col_mean, inds[1]) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format data into numpy arrays to be used in sklearn models\n",
    "Y = np.array(final[\"label\"])\n",
    "X = final.drop(columns = [\"label\"])\n",
    "X = inf_to_mean(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_colnames = final.drop(columns = [\"label\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize penalized logistic regression\n",
    "lr = LogisticRegression(max_iter = 10000, penalty = \"l1\", solver = \"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Cross Validation over L1 penalty coefficient\n",
    "cv = GridSearchCV(lr, param_grid = {\n",
    "    \"C\":[0.01, 0.1, 1, 100, 1000]},\n",
    "                 scoring = \"accuracy\",\n",
    "                 cv = 15\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform CV\n",
    "cv.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show CV Results\n",
    "lr_cv_results = pd.DataFrame(cv.cv_results_).sort_values(\"rank_test_score\")\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = cv.best_estimator_\n",
    "best_models[\"logistic\"] = best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chosen_coefs = len([x for x in best_lr.coef_.reshape(-1) if x != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables chosen by the Lasso model and their coefficients\n",
    "print(\"Coefficients:\")\n",
    "lr_coef_best_idx = np.flip(np.argsort(np.abs(best_lr.coef_).reshape(-1)))\n",
    "lr_coef_best = best_lr.coef_.reshape(-1)[lr_coef_best_idx]\n",
    "coef_touse = []\n",
    "coef_toexclude = []\n",
    "for idx, coef in zip(lr_coef_best_idx, lr_coef_best):\n",
    "    if coef != 0:\n",
    "        print(f\"{X_colnames[idx]}: {coef}\")\n",
    "        coef_touse.append(X_colnames[idx])\n",
    "    else:\n",
    "        coef_toexclude.append(X_colnames[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost Model\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameter grid for cross-validation\n",
    "xgb_params = {\n",
    "    \"eta\":[0.01,0.1,0.2],\n",
    "    #\"min_child_weight\":[1, 5, 10],\n",
    "    \"max_depth\":list(np.arange(3,11, 2)),\n",
    "    \"gamma\" : [0, 0.1, 0.5],\n",
    "    \"subsample\":[0.5,1],\n",
    "    \"colsample_bytree\":[0.5,1],\n",
    "    \"alpha\":[0,1,10,100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize cross-validation over selected parameters\n",
    "cv = GridSearchCV(xgb, param_grid = xgb_params,\n",
    "                 scoring = \"accuracy\",\n",
    "                 cv = 15\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cv_results = pd.DataFrame(cv.cv_results_).sort_values(\"rank_test_score\")\n",
    "xgb_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = cv.best_estimator_\n",
    "best_models[\"xgb\"] = best_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = best_xgb.feature_importances_\n",
    "fi_best_idx = np.flip(fi.argsort())\n",
    "fi_best = np.flip(np.sort(fi))\n",
    "print(\"MOST IMPORTANT FEATURES:\\n\")\n",
    "for i in range(len(fi_best_idx)):\n",
    "    print(\"Feature name: {:>12}     Feature importance: {:>12}\".format(X_colnames[fi_best_idx[i]], fi_best[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_linear_svm = GridSearchCV(SVC(kernel = \"linear\"), param_grid = {\n",
    "    \"C\":[1, 10, 100]\n",
    "})\n",
    "cv_linear_svm.fit(X,Y)\n",
    "best_linear_svm = cv_linear_svm.best_estimator_\n",
    "best_models[\"linear_svm\"] = best_linear_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rbf_svm = GridSearchCV(SVC(kernel = \"rbf\"), param_grid = {\n",
    "    \"C\":[1, 10, 100]\n",
    "})\n",
    "cv_linear_svm.fit(X,Y)\n",
    "best_rbf_svm = cv_rbf_svm.best_estimator_\n",
    "best_models[\"rbf_svm\"] = best_rbf_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_poly_svm = GridSearchCV(SVC(kernel = \"poly\"), param_grid = {\n",
    "    \"C\":[1, 10, 100],\n",
    "    \"degree\":[2,3,5]\n",
    "})\n",
    "cv_poly_svm.fit(X,Y)\n",
    "best_poly_svm = cv_poly_svm.best_estimator_\n",
    "best_models[\"poly_svm\"] = best_poly_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLS Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_rbf = Pipeline([(\"pls\", PLSRegression()), (\"rbf_svm\", SVC(kernel = \"rbf\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_rbf_cv_preds = cross_val_predict(pls_rbf, X, Y, cv = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_linear = Pipeline([(\"pls\", PLSRegression()), (\"linear_svm\", SVC(kernel = \"linear\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_linear_cv_preds = cross_val_predict(pls_linear, X, Y, cv = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_polynomial = Pipeline([(\"pls\", PLSRegression()), (\"poly_svm\", SVC(kernel = \"poly\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_polynomial_cv_preds = cross_val_predict(pls_polynomial, X, Y, cv = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_lr = Pipeline([(\"pls\", PLSRegression()), (\"logistic\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_lr_cv_preds = cross_val_predict(pls_lr, X, Y, cv = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [(\"This is a TODO my guy!\", \"Model should go here when it's time (TODO!)\")]\n",
    "final_estimator = LogisticRegression(max_iter = 10000, penalty = \"l1\", solver = \"liblinear\")\n",
    "stacking_estimator = StackingClassifier(estimators = model_list, final_estimator = final_estimator, cv = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = cross_val_predict(stacking_estimator, X, Y, cv = 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
